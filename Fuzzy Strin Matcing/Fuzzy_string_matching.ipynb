{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy String Matching in Python\n",
    "\n",
    "There are many strings that referring to the same things but they are written slightly different, misspelled, have typos or written with the capital or small words.\n",
    "\n",
    "During this project we want to match the fuzzy strings. Despite of lowering the words extra dot leads to the problem.\n",
    "\n",
    "#   The Levenshtein Package\n",
    "This metric calculates the minimum number of edits that is necessary to transform one word to other one. This metric was named after Vladimir Levenshtein, who originally considered it in 1965.\n",
    "\n",
    "![Vladimir Levenshtein](lev.jpeg)\n",
    "\n",
    "\n",
    "The package contains two functions which is written below\n",
    "Detailed informations can be found in Wikipedia.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Levenshtein_distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Apple Inc.\"\n",
    "Str2 = \"apple Inc\"\n",
    "Result = Str1.lower() == Str2.lower()\n",
    "print(Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein as lev\n",
    "Str1 = \"Apple Inc.\"\n",
    "Str2 = \"apple Inc\"\n",
    "Distance = lev.distance(Str1.lower(),Str2.lower()),\n",
    "print(Distance)\n",
    "Ratio = lev.ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  fuzzywuzzy\n",
    "Similar to levenshtein, a ratio function that computes the standard Levenshtein distance similarity ratio between two sequences. You can see an example below.\n",
    "\n",
    "\n",
    "<b>fuzz.ratio:</b> That ratio of similarity is the same as Levenshtein\n",
    "\n",
    "<b>fuzz.partial_ratio():</b> The way this works is by using an \"optimal partial\" logic. In other words, if the short string has length k and the longer string has the length m, then the algorithm seeks the score of the best matching length-k substring.\n",
    "\n",
    "The fuzz.token functions have an important advantage over ratio and partial_ratio. They tokenize the strings and preprocess them by turning them to lower case and getting rid of punctuation. In the case of <b>fuzz.token_sort_ratio()</b>, the string tokens get sorted alphabetically and then joined together. After that, a simple fuzz.ratio() is applied to obtain the similarity percentage. This allows cases such as court cases in this example to be marked as being the same.\n",
    "\n",
    "95% similarity is that magic? No, it's just string preprocessing under the hood. In particular, <b>fuzz.token_set_ratio()</b> takes a more flexible approach than fuzz.token_sort_ratio(). Instead of just tokenizing the strings, sorting and then pasting the tokens back together, token_set_ratio performs a set operation that takes out the common tokens (the intersection) and then makes fuzz.ratio() pairwise comparisons between the following new strings:\n",
    "\n",
    "\n",
    "intersection-only and the intersection with remainder of string one\n",
    "intersection-only and the intersection with remainder of string two\n",
    "intersection with remainder of one and intersection with remainder of two,\n",
    "\n",
    "Attempts to rule out differences in the strings. Calls ratio on three particular substring sets and returns the max (code):\n",
    "Notice that by splitting up the intersection and remainders of the two strings, we're accounting for both how similar and different the two strings are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "Str1 = \"The supreme court case of Nixon vs The United States\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "Token_Set_Ratio = fuzz.token_set_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)\n",
    "print(Token_Set_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuzzywuzzy package has a module called process that allows you to calculate the string with the highest similarity out of a vector of strings. You can see how this works below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Apple Inc.', 100), ('apple incorporated', 90), ('apple park', 67), ('iphone', 30)]\n",
      "('Apple Inc.', 100)\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "str2Match = \"apple inc\"\n",
    "strOptions = [\"Apple Inc.\",\"apple park\",\"apple incorporated\",\"iphone\"]\n",
    "Ratios = process.extract(str2Match,strOptions)\n",
    "print(Ratios)\n",
    "# You can also select the string with the highest matching percentage\n",
    "highest = process.extractOne(str2Match,strOptions)\n",
    "print(highest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for a person's name in a database: \n",
    "\n",
    "## NYSIIS \n",
    "Searching for a person's name in a database  is a unique challenge. Depending on the source and age of the data, you may not be able to count on the spelling of the name being correct, or even the same name being spelled the same way when it appears more than once.  \n",
    "\n",
    "A common way to solve the string-search problem is to look for values that are \"close\" to the same as the search target. Using a traditional \"fuzzy match\" algorithm to compute the closeness of two arbitrary strings is expensive, though, and it isn't appropriate for searching large data sets. \n",
    "\n",
    "\n",
    "A better solution is to compute hash values for entries in the database in advance, and several special hash algorithms have been created for this purpose. These phonetic hash algorithms allow you to compare two words or names based on how they sound, rather than the precise spelling.\n",
    "\n",
    "\n",
    "## DMetaphone \n",
    "The Metaphone algorithm is significantly more complicated than the others because it includes special rules for handling spelling inconsistencies and for looking at combinations of consonants in addition to some vowels. An updated version of the algorithm, called Double Metaphone, goes even further by adding rules for handling some spellings and pronunciations from languages other than English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catherine            CATARAN\n",
      "Katherine            CATARAN\n",
      "Katarina             CATARAN\n",
      "Johnathan            JANATAN\n",
      "Jonathan             JANATAN\n",
      "John                 JAN\n",
      "Teresa               TARAS\n",
      "Theresa              TARAS\n",
      "Smith                SNATH\n",
      "Smyth                SNATH\n",
      "Jessica              JASAC\n",
      "Joshua               JAS\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import fuzzy\n",
    "\n",
    "names = [ 'Catherine', 'Katherine', 'Katarina',\n",
    "          'Johnathan', 'Jonathan', 'John',\n",
    "          'Teresa', 'Theresa',\n",
    "          'Smith', 'Smyth',\n",
    "          'Jessica',\n",
    "          'Joshua',\n",
    "          ]\n",
    "\n",
    "for n in names:\n",
    "    print('%-20s' % n, fuzzy.nysiis(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: \n",
    "\n",
    "The dataset it the list of best selling book published by New York Times since  1930. We want to see the variation of gender distubution of authors during the time. The initial dataset is from 2008 to 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pandas module\n",
    "import pandas as pd\n",
    "\n",
    "# Reading in datasets/nytkids_yearly.csv, which is semicolon delimited.\n",
    "author_df = pd.read_csv('datasets/kids_book.csv', delimiter=';')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Besteller this year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>DRAGONS LOVE TACOS</td>\n",
       "      <td>Adam Rubin</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>THE WONDERFUL THINGS YOU WILL BE</td>\n",
       "      <td>Emily Winfield Martin</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>THE DAY THE CRAYONS QUIT</td>\n",
       "      <td>Drew Daywalt</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>ROSIE REVERE, ENGINEER</td>\n",
       "      <td>Andrea Beaty</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>ADA TWIST, SCIENTIST</td>\n",
       "      <td>Andrea Beaty</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                        Book Title                 Author  \\\n",
       "0  2017                DRAGONS LOVE TACOS             Adam Rubin   \n",
       "1  2017  THE WONDERFUL THINGS YOU WILL BE  Emily Winfield Martin   \n",
       "2  2017          THE DAY THE CRAYONS QUIT           Drew Daywalt   \n",
       "3  2017            ROSIE REVERE, ENGINEER           Andrea Beaty   \n",
       "4  2017              ADA TWIST, SCIENTIST           Andrea Beaty   \n",
       "\n",
       "   Besteller this year  \n",
       "0                   49  \n",
       "1                   48  \n",
       "2                   44  \n",
       "3                   38  \n",
       "4                   28  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df[\"First_name\"] = author_df[\"Author\"].str.split(\" \", n = 1, expand = True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a new column or list that contains the phonetic equivalent of every first name that we just extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Besteller this year</th>\n",
       "      <th>First_name</th>\n",
       "      <th>Fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>DRAGONS LOVE TACOS</td>\n",
       "      <td>Adam Rubin</td>\n",
       "      <td>49</td>\n",
       "      <td>Adam</td>\n",
       "      <td>ADAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>THE WONDERFUL THINGS YOU WILL BE</td>\n",
       "      <td>Emily Winfield Martin</td>\n",
       "      <td>48</td>\n",
       "      <td>Emily</td>\n",
       "      <td>ENALY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>THE DAY THE CRAYONS QUIT</td>\n",
       "      <td>Drew Daywalt</td>\n",
       "      <td>44</td>\n",
       "      <td>Drew</td>\n",
       "      <td>DR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>ROSIE REVERE, ENGINEER</td>\n",
       "      <td>Andrea Beaty</td>\n",
       "      <td>38</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>ANDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>ADA TWIST, SCIENTIST</td>\n",
       "      <td>Andrea Beaty</td>\n",
       "      <td>28</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>ANDR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                        Book Title                 Author  \\\n",
       "0  2017                DRAGONS LOVE TACOS             Adam Rubin   \n",
       "1  2017  THE WONDERFUL THINGS YOU WILL BE  Emily Winfield Martin   \n",
       "2  2017          THE DAY THE CRAYONS QUIT           Drew Daywalt   \n",
       "3  2017            ROSIE REVERE, ENGINEER           Andrea Beaty   \n",
       "4  2017              ADA TWIST, SCIENTIST           Andrea Beaty   \n",
       "\n",
       "   Besteller this year First_name  Fuzzy  \n",
       "0                   49       Adam   ADAN  \n",
       "1                   48      Emily  ENALY  \n",
       "2                   44       Drew     DR  \n",
       "3                   38     Andrea   ANDR  \n",
       "4                   28     Andrea   ANDR  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_df[\"Fuzzy\"] = [fuzzy.nysiis(n) for n in author_df[\"First_name\"]]\n",
    "author_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_name_unique = np.unique(author_df['First_name'])\n",
    "fuzzy_unique = np.unique(author_df['Fuzzy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify if a name is male or female we use the dataset of Social Security Administrationâ€™s baby name data. We add the new colum for higher probability of a girl or a boy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>babynysiis</th>\n",
       "      <th>perc_female</th>\n",
       "      <th>perc_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>62.50</td>\n",
       "      <td>37.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAX</td>\n",
       "      <td>63.64</td>\n",
       "      <td>36.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESAR</td>\n",
       "      <td>44.44</td>\n",
       "      <td>55.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DJANG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PARCAL</td>\n",
       "      <td>25.00</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  babynysiis  perc_female  perc_male\n",
       "0        NaN        62.50      37.50\n",
       "1        RAX        63.64      36.36\n",
       "2       ESAR        44.44      55.56\n",
       "3      DJANG         0.00     100.00\n",
       "4     PARCAL        25.00      75.00"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babies_df = pd.read_csv('datasets/babynames_nysiis.csv', delimiter = ';')\n",
    "babies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamid/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "babies_df['gender'] = 'M'\n",
    "\n",
    "for i in range(len(babies_df)):\n",
    "    if babies_df['perc_female'][i] > babies_df['perc_male'][i]: \n",
    "       babies_df['gender'][i] = 'F'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>babynysiis</th>\n",
       "      <th>perc_female</th>\n",
       "      <th>perc_male</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>62.50</td>\n",
       "      <td>37.50</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAX</td>\n",
       "      <td>63.64</td>\n",
       "      <td>36.36</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESAR</td>\n",
       "      <td>44.44</td>\n",
       "      <td>55.56</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DJANG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PARCAL</td>\n",
       "      <td>25.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VALCARY</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FRANCASC</td>\n",
       "      <td>63.64</td>\n",
       "      <td>36.36</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CABAT</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XANDAR</td>\n",
       "      <td>16.67</td>\n",
       "      <td>83.33</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RACSAN</td>\n",
       "      <td>33.33</td>\n",
       "      <td>66.67</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  babynysiis  perc_female  perc_male gender\n",
       "0        NaN        62.50      37.50      F\n",
       "1        RAX        63.64      36.36      F\n",
       "2       ESAR        44.44      55.56      M\n",
       "3      DJANG         0.00     100.00      M\n",
       "4     PARCAL        25.00      75.00      M\n",
       "5    VALCARY       100.00       0.00      F\n",
       "6   FRANCASC        63.64      36.36      F\n",
       "7      CABAT        50.00      50.00      M\n",
       "8     XANDAR        16.67      83.33      M\n",
       "9     RACSAN        33.33      66.67      M"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "babies_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-1b796d301558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fuzzy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbabies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'babynysiis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbabies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'babynysiis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mauthor_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Fuzzy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbabies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'babynysiis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(author_df['Fuzzy'])):\n",
    "      for j in list(babies_df['babynysiis']):\n",
    "            list(babies_df['babynysiis']).index(j) if author_df[\"Fuzzy\"][i] in list(babies_df['babynysiis']) else -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for j in list(babies_df['babynysiis']):\n",
    "list(babies_df['babynysiis']).index('VALCARY') if author_df[\"Fuzzy\"][1] in list(babies_df['babynysiis']) else -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df['B'].isin(['one','three'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Besteller this year</th>\n",
       "      <th>First_name</th>\n",
       "      <th>Fuzzy</th>\n",
       "      <th>author_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>DRAGONS LOVE TACOS</td>\n",
       "      <td>Adam Rubin</td>\n",
       "      <td>49</td>\n",
       "      <td>Adam</td>\n",
       "      <td>ADAN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>THE WONDERFUL THINGS YOU WILL BE</td>\n",
       "      <td>Emily Winfield Martin</td>\n",
       "      <td>48</td>\n",
       "      <td>Emily</td>\n",
       "      <td>ENALY</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>THE DAY THE CRAYONS QUIT</td>\n",
       "      <td>Drew Daywalt</td>\n",
       "      <td>44</td>\n",
       "      <td>Drew</td>\n",
       "      <td>DR</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>ROSIE REVERE, ENGINEER</td>\n",
       "      <td>Andrea Beaty</td>\n",
       "      <td>38</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>ANDR</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>ADA TWIST, SCIENTIST</td>\n",
       "      <td>Andrea Beaty</td>\n",
       "      <td>28</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>ANDR</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                        Book Title                 Author  \\\n",
       "0  2017                DRAGONS LOVE TACOS             Adam Rubin   \n",
       "1  2017  THE WONDERFUL THINGS YOU WILL BE  Emily Winfield Martin   \n",
       "2  2017          THE DAY THE CRAYONS QUIT           Drew Daywalt   \n",
       "3  2017            ROSIE REVERE, ENGINEER           Andrea Beaty   \n",
       "4  2017              ADA TWIST, SCIENTIST           Andrea Beaty   \n",
       "\n",
       "   Besteller this year First_name  Fuzzy author_gender  \n",
       "0                   49       Adam   ADAN       Unknown  \n",
       "1                   48      Emily  ENALY       Unknown  \n",
       "2                   44       Drew     DR       Unknown  \n",
       "3                   38     Andrea   ANDR       Unknown  \n",
       "4                   28     Andrea   ANDR       Unknown  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function returns the location of an element in a_list.\n",
    "# Where an item does not exist, it returns -1.\n",
    "def locate_in_list(a_list, element):\n",
    "   loc_of_name = a_list.index(element) if element in a_list else -1\n",
    "   return(loc_of_name)\n",
    "\n",
    "\n",
    "# Looping through author_df['nysiis_name'] and appending the gender of each\n",
    "# author to author_gender.\n",
    "author_gender = []\n",
    "#print(author_df['nysiis_name'])\n",
    "for i in author_df['Fuzzy']:\n",
    "   index = locate_in_list(list(babies_df['gender']),i)\n",
    "   #print(index)\n",
    "   if(index==-1): \n",
    "       author_gender.append('Unknown')\n",
    "   else: \n",
    "       author_gender.append(list(babies_df['gender'])[index])\n",
    "\n",
    "author_df['author_gender'] = author_gender \n",
    "\n",
    "author_df['author_gender'].value_counts()\n",
    "\n",
    "author_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = list(babies_df['gender'])[0]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_of_name = a_list.index(element) if element in a_list else -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'F',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  'M',\n",
       "  'M',\n",
       "  'F',\n",
       "  ...],\n",
       " 1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(babies_df['gender']),1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gender'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gender'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-697a4aaf4595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbabies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'perc_female'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbabies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'perc_male'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbabies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbabies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'M'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gender'"
     ]
    }
   ],
   "source": [
    "if babies_df['perc_female'][0] > babies_df['perc_male'][0]: \n",
    "    babies_df['gender'][0] = 'F'\n",
    "else:\n",
    "    babies_df['gender'][0] = 'M'\n",
    "    \n",
    "print(babies_df['gender'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gender_guesser.detector as gender\n",
    ">>> d = gender.Detector()\n",
    ">>> print(d.get_gender(u\"Bob\"))\n",
    "male\n",
    ">>> print(d.get_gender(u\"Sally\"))\n",
    "female\n",
    ">>> print(d.get_gender(u\"Pauley\")) # should be androgynous\n",
    "andy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
